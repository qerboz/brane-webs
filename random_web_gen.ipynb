{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "3GTkB2kVj6zV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.functional import pairwise_distance, relu, softmax\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wszgDYmxj6zY"
      },
      "outputs": [],
      "source": [
        "class TripletDataset(Dataset):\n",
        "    def __init__(self, df, transform=None):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        anchor_row = self.df.iloc[idx]\n",
        "        anchor = torch.tensor(anchor_row['web'], dtype=torch.float32)\n",
        "        label = anchor_row['strong-class']\n",
        "        positive_idx = ((self.df['strong-class'] == label) & (self.df.index != idx))\n",
        "        positive_row = self.df.loc[positive_idx].sample(n=1)\n",
        "        positive = torch.tensor(positive_row['web'].values[0], dtype=torch.float32)\n",
        "        negative_idx = self.df['weak-class'] != label\n",
        "        negative_row = self.df.loc[negative_idx].sample(n=1)\n",
        "        negative = torch.tensor(negative_row['web'].values[0], dtype=torch.float32)\n",
        "        if self.transform:\n",
        "            anchor = self.transform(anchor)\n",
        "            positive = self.transform(positive)\n",
        "            negative = self.transform(negative)\n",
        "        return anchor, positive, negative\n",
        "\n",
        "class TripletDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, df, train_size=0.8, val_size=0.1, test_size=0.1, batch_size=32, transform = None):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.train_size = train_size\n",
        "        self.val_size = val_size\n",
        "        self.test_size = test_size\n",
        "        self.batch_size = batch_size\n",
        "        self.transform = transform\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        n = self.df['strong-class'].max()\n",
        "        train_end = int(self.train_size * n)\n",
        "        val_end = train_end + int(self.val_size * n)\n",
        "        indices = np.random.permutation(n)\n",
        "        train_indices = indices[:train_end]\n",
        "        val_indices = indices[train_end:val_end]\n",
        "        test_indices = indices[val_end:]\n",
        "        self.train_dataset = TripletDataset(self.df[self.df['strong-class'].isin(train_indices)], transform=self.transform)\n",
        "        self.val_dataset = TripletDataset(self.df[self.df['strong-class'].isin(val_indices)], transform=self.transform)\n",
        "        self.test_dataset = TripletDataset(self.df[self.df['strong-class'].isin(test_indices)], transform=self.transform)\n",
        "\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxVpRsmFj6zZ"
      },
      "outputs": [],
      "source": [
        "dataloader = TripletDataModule(df)\n",
        "dataloader.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KgYKBjOJj6zZ"
      },
      "outputs": [],
      "source": [
        "class SiameseNet(pl.LightningModule):\n",
        "    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, learning_rate = 1e-3, loss_margin = 1):\n",
        "        super().__init__()\n",
        "        self.fc1 = torch.nn.Linear(input_size, hidden_size1)\n",
        "        self.fc2 = torch.nn.Linear(hidden_size1, hidden_size2)\n",
        "        self.fc3 = torch.nn.Linear(hidden_size2, output_size)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.loss = torch.nn.TripletMarginLoss(loss_margin)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.flatten(x,start_dim=1)\n",
        "        x = self.fc1(x)\n",
        "        x = relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = softmax(x)\n",
        "        return x\n",
        "\n",
        "    def shared_step(self, anchor, positive, negative):\n",
        "        anchor_embedding = self.forward(anchor)\n",
        "        positive_embedding = self.forward(positive)\n",
        "        negative_embedding = self.forward(negative)\n",
        "        return anchor_embedding, positive_embedding, negative_embedding\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        anchor, positive, negative = batch\n",
        "        anchor_embedding, positive_embedding, negative_embedding = self.shared_step(anchor, positive, negative)\n",
        "        loss = self.loss(anchor_embedding, positive_embedding, negative_embedding)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        anchor, positive, negative = batch\n",
        "        anchor_embedding, positive_embedding, negative_embedding = self.shared_step(anchor, positive, negative)\n",
        "        loss = self.loss(anchor_embedding, positive_embedding, negative_embedding)\n",
        "        self.log('val_loss', loss)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "        return optimizer\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        anchor, positive, negative = batch\n",
        "        anchor_embedding, positive_embedding, negative_embedding = self.shared_step(anchor, positive, negative)\n",
        "        distance_positive = pairwise_distance(anchor_embedding, positive_embedding)\n",
        "        distance_negative = pairwise_distance(anchor_embedding, negative_embedding)\n",
        "        return {\n",
        "            'distance_positive': distance_positive,\n",
        "            'distance_negative': distance_negative,\n",
        "        }\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        distances_positive = torch.cat([o['distance_positive'] for o in outputs])\n",
        "        distances_negative = torch.cat([o['distance_negative'] for o in outputs])\n",
        "        y_pred = (distances_positive < distances_negative).to(torch.float32)\n",
        "        accuracy = y_pred.float().mean()\n",
        "        self.log('test_accuracy', accuracy, prog_bar=True)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jmPdmGRij6zZ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "GPU available: False, used: False\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n"
          ]
        }
      ],
      "source": [
        "first_net = SiameseNet(6,200,200,50)\n",
        "trainer = pl.Trainer(max_epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RRSIOysj6za"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/antoine/miniforge3/envs/torch-m1/lib/python3.10/site-packages/pytorch_lightning/core/datamodule.py:469: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  rank_zero_deprecation(\n",
            "\n",
            "  | Name | Type              | Params\n",
            "-------------------------------------------\n",
            "0 | fc1  | Linear            | 1.4 K \n",
            "1 | fc2  | Linear            | 40.2 K\n",
            "2 | fc3  | Linear            | 10.1 K\n",
            "3 | loss | TripletMarginLoss | 0     \n",
            "-------------------------------------------\n",
            "51.6 K    Trainable params\n",
            "0         Non-trainable params\n",
            "51.6 K    Total params\n",
            "0.207     Total estimated model params size (MB)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5026cb71f9474d3394c7e8ed5b42fb3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/antoine/miniforge3/envs/torch-m1/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/var/folders/dj/d8z3jgzs71z1844rhj9ypsyw0000gn/T/ipykernel_12906/4158955810.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = softmax(x)\n",
            "/Users/antoine/miniforge3/envs/torch-m1/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28537da6b0ff4d64b25511978a6fa747",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/antoine/miniforge3/envs/torch-m1/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
            "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
          ]
        }
      ],
      "source": [
        "trainer.fit(first_net,dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/antoine/miniforge3/envs/torch-m1/lib/python3.10/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "900c65d5f01143ee915cd19984bb7a9f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/dj/d8z3jgzs71z1844rhj9ypsyw0000gn/T/ipykernel_22330/4158955810.py:17: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  x = softmax(x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_accuracy': 0.644481897354126}\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'test_accuracy': 0.644481897354126}]"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.test(first_net,dataloader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "torch-m1",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
